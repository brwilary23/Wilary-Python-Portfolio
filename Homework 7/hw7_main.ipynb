{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spaCy to set up code\n",
    "import spacy\n",
    "#load correct spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The\n",
      "Head: fox\n",
      "Lemma: the\n",
      "Morph: Definite=Def|PronType=Art\n",
      "\n",
      "Text: quick\n",
      "Head: fox\n",
      "Lemma: quick\n",
      "Morph: Degree=Pos\n",
      "\n",
      "Text: brown\n",
      "Head: fox\n",
      "Lemma: brown\n",
      "Morph: Degree=Pos\n",
      "\n",
      "Text: fox\n",
      "Head: jump\n",
      "Lemma: fox\n",
      "Morph: Number=Sing\n",
      "\n",
      "Text: does\n",
      "Head: jump\n",
      "Lemma: do\n",
      "Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "Text: n't\n",
      "Head: jump\n",
      "Lemma: not\n",
      "Morph: Polarity=Neg\n",
      "\n",
      "Text: jump\n",
      "Head: jump\n",
      "Lemma: jump\n",
      "Morph: VerbForm=Inf\n",
      "\n",
      "Text: over\n",
      "Head: jump\n",
      "Lemma: over\n",
      "Morph: \n",
      "\n",
      "Text: the\n",
      "Head: dog\n",
      "Lemma: the\n",
      "Morph: Definite=Def|PronType=Art\n",
      "\n",
      "Text: lazy\n",
      "Head: dog\n",
      "Lemma: lazy\n",
      "Morph: Degree=Pos\n",
      "\n",
      "Text: dog\n",
      "Head: over\n",
      "Lemma: dog\n",
      "Morph: Number=Sing\n",
      "\n",
      "Text: .\n",
      "Head: jump\n",
      "Lemma: .\n",
      "Morph: PunctType=Peri\n",
      "\n",
      "Text: Natural\n",
      "Head: Language\n",
      "Lemma: Natural\n",
      "Morph: Number=Sing\n",
      "\n",
      "Text: Language\n",
      "Head: Processing\n",
      "Lemma: Language\n",
      "Morph: Number=Sing\n",
      "\n",
      "Text: Processing\n",
      "Head: is\n",
      "Lemma: processing\n",
      "Morph: Number=Sing\n",
      "\n",
      "Text: is\n",
      "Head: is\n",
      "Lemma: be\n",
      "Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "Text: fascinating\n",
      "Head: is\n",
      "Lemma: fascinating\n",
      "Morph: Degree=Pos\n",
      "\n",
      "Text: !\n",
      "Head: is\n",
      "Lemma: !\n",
      "Morph: PunctType=Peri\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#bring in the text quote\n",
    "text = \"The quick brown fox doesn't jump over the lazy dog. Natural Language Processing is fascinating!\"\n",
    "doc = nlp(text)\n",
    "\n",
    "#tokenized loop\n",
    "for token in doc:\n",
    "    print(f\"Text: {token.text}\")\n",
    "    print(f\"Head: {token.head}\")\n",
    "    print(f\"Lemma: {token.lemma_}\")\n",
    "    print(f\"Morph: {token.morph}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The spaCy processes the various tokens by switching it into a doc container, which separates the text by the quantity of words, with each token being self-contained with syntatic purpose. \n",
    "2. The spaCy uses punctuation marks as individual tokens.\n",
    "3. When the text includes contractions, spaCy separates them into two tokens because the contractions represent two words. For instance, \"don't\" will be separeated into \"do\" and \"n't\", which represent \"do\" and \"not\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The\n",
      "POS: DET\n",
      "Tag: DT\n",
      "\n",
      "Text: quick\n",
      "POS: ADJ\n",
      "Tag: JJ\n",
      "\n",
      "Text: brown\n",
      "POS: ADJ\n",
      "Tag: JJ\n",
      "\n",
      "Text: fox\n",
      "POS: NOUN\n",
      "Tag: NN\n",
      "\n",
      "Text: does\n",
      "POS: AUX\n",
      "Tag: VBZ\n",
      "\n",
      "Text: n't\n",
      "POS: PART\n",
      "Tag: RB\n",
      "\n",
      "Text: jump\n",
      "POS: VERB\n",
      "Tag: VB\n",
      "\n",
      "Text: over\n",
      "POS: ADP\n",
      "Tag: IN\n",
      "\n",
      "Text: the\n",
      "POS: DET\n",
      "Tag: DT\n",
      "\n",
      "Text: lazy\n",
      "POS: ADJ\n",
      "Tag: JJ\n",
      "\n",
      "Text: dog\n",
      "POS: NOUN\n",
      "Tag: NN\n",
      "\n",
      "Text: .\n",
      "POS: PUNCT\n",
      "Tag: .\n",
      "\n",
      "Text: Natural\n",
      "POS: PROPN\n",
      "Tag: NNP\n",
      "\n",
      "Text: Language\n",
      "POS: PROPN\n",
      "Tag: NNP\n",
      "\n",
      "Text: Processing\n",
      "POS: NOUN\n",
      "Tag: NN\n",
      "\n",
      "Text: is\n",
      "POS: AUX\n",
      "Tag: VBZ\n",
      "\n",
      "Text: fascinating\n",
      "POS: ADJ\n",
      "Tag: JJ\n",
      "\n",
      "Text: !\n",
      "POS: PUNCT\n",
      "Tag: .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#goes through each token to look at position and tag\n",
    "for token in doc:\n",
    "    print(f\"Text: {token.text}\")\n",
    "    print(f\"POS: {token.pos_}\")\n",
    "    print(f\"Tag: {token.tag_}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The POS tag for \"quick\" is ADJ, the POS tag for \"jump\" is VERB, and the POS tag for \"is\" is AUX.\n",
    "2. POS tagging may be useful for grammar checking or machine translation because it allows one to figure out when words are used wrong, to help better identify correct sentence structure, and to improve AI understanding of how words are used together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama PERSON\n",
      "44th ORDINAL\n",
      "the United States GPE\n",
      "Hawaii GPE\n"
     ]
    }
   ],
   "source": [
    "#brings in the obama text\n",
    "text2 = \"Barack Obama was the 44th President of the United States. He was born in Hawaii.\"\n",
    "doc2 = nlp(text2)\n",
    "\n",
    "#goes through the ents in the doc\n",
    "for ent in doc2.ents:\n",
    "    print (ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"Barack Obama\", \"44th\", \"the United States\", and \"Hawaii\" are all identified as named entities.\n",
    "2. \"Barack Obama\" is assigned to the entity type Person, while \"Hawaii\" is assigned to the entity type GPE (Geopolitical Entity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1:\n",
      "Doc 3:\n",
      "Brynn ORG\n",
      "Jack PERSON\n",
      "Cecilia GPE\n",
      "Doc 4:\n",
      "Brynn ORG\n",
      "Jack PERSON\n",
      "Doc 5:\n",
      "brynn enjoys PERSON\n",
      "jack PERSON\n"
     ]
    }
   ],
   "source": [
    "#text to try\n",
    "text3 = \"Brynn likes to code. Her coding partners are Jack and Cecilia.\"\n",
    "text4 = \"Coding is Brynn's favorite subject! Jack and Ceci are her coding partners!\"\n",
    "text5 = \"brynn enjoys her favorite subject, coding, with her coding partners, jack and cecilia.\"\n",
    "\n",
    "doc3 = nlp(text3)\n",
    "doc4 = nlp(text4)\n",
    "doc5 = nlp(text5)\n",
    "\n",
    "#ents tests, trial 1\n",
    "print(\"Trial 1:\")\n",
    "print(\"Doc 3:\")\n",
    "for ent in doc3.ents:\n",
    "    print (ent.text, ent.label_)\n",
    "print(\"Doc 4:\")\n",
    "for ent in doc4.ents:\n",
    "    print (ent.text, ent.label_)\n",
    "print(\"Doc 5:\")\n",
    "for ent in doc5.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2:\n",
      "Doc 3:\n",
      "Brynn NNP\n",
      "likes VBZ\n",
      "to TO\n",
      "code VB\n",
      ". .\n",
      "Her PRP$\n",
      "coding VBG\n",
      "partners NNS\n",
      "are VBP\n",
      "Jack NNP\n",
      "and CC\n",
      "Cecilia NNP\n",
      ". .\n",
      "Doc 4:\n",
      "Coding NN\n",
      "is VBZ\n",
      "Brynn NNP\n",
      "'s POS\n",
      "favorite JJ\n",
      "subject NN\n",
      "! .\n",
      "Jack NNP\n",
      "and CC\n",
      "Ceci NNP\n",
      "are VBP\n",
      "her PRP$\n",
      "coding VBG\n",
      "partners NNS\n",
      "! .\n",
      "Doc 5:\n",
      "brynn NNP\n",
      "enjoys VBZ\n",
      "her PRP$\n",
      "favorite JJ\n",
      "subject NN\n",
      ", ,\n",
      "coding NN\n",
      ", ,\n",
      "with IN\n",
      "her PRP$\n",
      "coding VBG\n",
      "partners NNS\n",
      ", ,\n",
      "jack NN\n",
      "and CC\n",
      "cecilia NN\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "#tag test, trial 2\n",
    "print(\"Trial 2:\")\n",
    "print(\"Doc 3:\")\n",
    "for token in doc3:\n",
    "    print (token.text, token.tag_)\n",
    "print(\"Doc 4:\")\n",
    "for token in doc4:\n",
    "    print (token.text, token.tag_)\n",
    "print(\"Doc 5:\")\n",
    "for token in doc5:\n",
    "    print (token.text, token.tag_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3:\n",
      "Doc 3:\n",
      "Brynn likes\n",
      "likes likes\n",
      "to code\n",
      "code likes\n",
      ". likes\n",
      "Her partners\n",
      "coding partners\n",
      "partners are\n",
      "are are\n",
      "Jack are\n",
      "and Jack\n",
      "Cecilia Jack\n",
      ". are\n",
      "Doc 4:\n",
      "Coding is\n",
      "is is\n",
      "Brynn subject\n",
      "'s Brynn\n",
      "favorite subject\n",
      "subject is\n",
      "! is\n",
      "Jack are\n",
      "and Jack\n",
      "Ceci Jack\n",
      "are are\n",
      "her partners\n",
      "coding partners\n",
      "partners are\n",
      "! are\n",
      "Doc 5:\n",
      "brynn enjoys\n",
      "enjoys enjoys\n",
      "her subject\n",
      "favorite subject\n",
      "subject enjoys\n",
      ", subject\n",
      "coding subject\n",
      ", coding\n",
      "with coding\n",
      "her partners\n",
      "coding partners\n",
      "partners with\n",
      ", partners\n",
      "jack partners\n",
      "and jack\n",
      "cecilia jack\n",
      ". enjoys\n"
     ]
    }
   ],
   "source": [
    "#part of speech test, trial 3\n",
    "print(\"Trial 3:\")\n",
    "print(\"Doc 3:\")\n",
    "for token in doc3:\n",
    "    print (token.text, token.head)\n",
    "print(\"Doc 4:\")\n",
    "for token in doc4:\n",
    "    print (token.text, token.head)\n",
    "print(\"Doc 5:\")\n",
    "for token in doc5:\n",
    "    print (token.text, token.head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 1: The system had great difficulty identifying the different names when lower case. It also referred to Cecilia as a GPE instead of a name, and refused to pick out Ceci as a person. Doc 5 also thought the person was \"brynn enjoys\" instead of just a verb.\n",
    "\n",
    "Trial 2: This was a lot more similar between trials. Most of the words were identified the same way, because they were read on their own. The biggest difference was the lowercase switch of identifying Jack and Ceci as NN instead of NNP due to the lowercase. \n",
    "\n",
    "Trial 3: I wrote the sentences differently, so even though they essentially said the same thing, the syntax was incredibly different between sentences! The system picked up on this!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
